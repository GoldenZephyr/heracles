# Heracles



## Setup

Pull the image:
```bash
docker pull neo4j:5.25.1
```

Run the database:
```bash
 docker run -d \
    --restart always \
    --publish=7474:7474 --publish=7687:7687 \
    neo4j:5.25.1
```

## Useful Queries

### Print distinct object classes in scene graph

```
db.query("MATCH (n: Object) RETURN DISTINCT n.class as class""")
```

### Print distinct object classes and counts
```
db.query("MATCH (n: Object) RETURN DISTINCT n.class as class, COUNT(*) as count""")
```

### Print center point of objects of specific class
```
db.query("MATCH (n: Object {class: 'tree'}) RETURN n.center as center""")
```

### Filter for objects of a certain type within a bounding box
```
db.query("""WITH point({x: -100, y: 16, z: -100}) AS lowerLeft,
                 point({x: -90, y: 22, z:100}) AS upperRight
            MATCH (t: Object {class: "tree"})
            WHERE point.withinBBox(t.center, lowerLeft, upperRight)
            RETURN t as result""")
```

### Filter for all objects of a certain type within 30 meters of given point
```
db.query(""" MATCH (t: Object {class: "tree"})
             WITH point.distance(point({x: -100, y:16, z:0}), t.center) as d, t
             WHERE d < 30
             RETURN t as obj, d as distance""")
```



## Development Notes

### Converting between `spark_dsg` and Neo4J schema

Currently there is a manual step of turning each `spark_dsg` node into a dictionary of its attributes, which is then used to fill in the graph database schema. It would be slightly cleaner if this dict was automatically generated by calling `vars()` or `__dict__` on the `spark_dsg` node, but those objects are lacking a `__dict__`, I assume because of pybind11-related reasons. I don't really want to deal with adding that functionality to our pybind11 `spark_dsg` interface, so for now we have this intermediate dictionary "representation"
